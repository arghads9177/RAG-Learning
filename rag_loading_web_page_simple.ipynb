{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5653e2d",
   "metadata": {},
   "source": [
    "# RAG Loading Data from Web Page in Simple and Fast Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b00ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87c8e38",
   "metadata": {},
   "source": [
    "## Load Data from Single Web Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3597a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_url = \"https://python.langchain.com/docs/how_to/document_loader_web/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493b083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401628fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4820a3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/how_to/document_loader_web/', 'title': 'How to load web pages | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'This guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nHow to load web pages | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\\uf8ffüí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\\uf8ffü¶ú\\uf8ffüõ†Ô∏è LangSmith\\uf8ffü¶ú\\uf8ffüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to load web pagesOn this pageHow to load web pages\\nThis guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.\\nLangChain integrates with a host of parsers that are appropriate for web pages. The right parser will depend on your needs. Below we demonstrate two possibilities:\\n\\nSimple and fast parsing, in which we recover one Document per web page with its content represented as a \"flattened\" string;\\nAdvanced parsing, in which we recover multiple Document objects per page, allowing one to identify and traverse sections, links, tables, and other structures.\\n\\nSetup‚Äã\\nFor the \"simple and fast\" parsing, we will need langchain-community and the beautifulsoup4 library:\\n%pip install -qU langchain-community beautifulsoup4\\nFor advanced parsing, we will use langchain-unstructured:\\n%pip install -qU langchain-unstructured\\nSimple and fast text extraction‚Äã\\nIf you are looking for a simple string representation of text that is embedded in a web page, the method below is appropriate. It will return a list of Document objects -- one per page -- containing a single string of the page\\'s text. Under the hood it uses the beautifulsoup4 Python library.\\nLangChain document loaders implement lazy_load and its async variant, alazy_load, which return iterators of Document objects. We will use these below.\\nimport bs4from langchain_community.document_loaders import WebBaseLoaderpage_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"loader = WebBaseLoader(web_paths=[page_url])docs = []async for doc in loader.alazy_load():    docs.append(doc)assert len(docs) == 1doc = docs[0]API Reference:WebBaseLoader\\nUSER_AGENT environment variable not set, consider setting it to identify your requests.\\nprint(f\"{doc.metadata}\\\\n\")print(doc.page_content[:500].strip())\\n{\\'source\\': \\'https://python.langchain.com/docs/how_to/chatbots_memory/\\', \\'title\\': \\'How to add memory to chatbots | \\\\uf8ff√º¬∂√∫√î‚àè√®\\\\uf8ff√º√Æ√≥ LangChain\\', \\'description\\': \\'A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:\\', \\'language\\': \\'en\\'}How to add memory to chatbots | Ô£ø√º¬∂√∫√î‚àè√®Ô£ø√º√Æ√≥ LangChainSkip to main contentShare your thoughts on AI agents. Take the 3-min survey.IntegrationsAPI ReferenceMoreContributingPeopleLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1Ô£ø√º√≠¬®SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a Simple LLM Application with LCELBuild a Query Analysis SystemBuild a ChatbotConversational RAGBuild an Extraction ChainBuild an AgentTaggingd\\nThis is essentially a dump of the text from the page\\'s HTML. It may contain extraneous information like headings and navigation bars. If you are familiar with the expected HTML, you can specify desired <div> classes and other parameters via BeautifulSoup. Below we parse only the body text of the article:\\nloader = WebBaseLoader(    web_paths=[page_url],    bs_kwargs={        \"parse_only\": bs4.SoupStrainer(class_=\"theme-doc-markdown markdown\"),    },    bs_get_text_kwargs={\"separator\": \" | \", \"strip\": True},)docs = []async for doc in loader.alazy_load():    docs.append(doc)assert len(docs) == 1doc = docs[0]\\nprint(f\"{doc.metadata}\\\\n\")print(doc.page_content[:500])\\n{\\'source\\': \\'https://python.langchain.com/docs/how_to/chatbots_memory/\\'}How to add memory to chatbots | A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including: | Simply stuffing previous messages into a chat model prompt. | The above, but trimming old messages to reduce the amount of distracting information the model has to deal with. | More complex modifications like synthesizing summaries for long running conversations. | We\\'ll go into more detail on a few techniq\\nprint(doc.page_content[-500:])\\na greeting. Nemo then asks the AI how it is doing, and the AI responds that it is fine.\\'), | HumanMessage(content=\\'What did I say my name was?\\'), | AIMessage(content=\\'You introduced yourself as Nemo. How can I assist you today, Nemo?\\')] | Note that invoking the chain again will generate another summary generated from the initial summary plus new messages and so on. You could also design a hybrid approach where a certain number of messages are retained in chat history while others are summarized.\\nNote that this required advance technical knowledge of how the body text is represented in the underlying HTML.\\nWe can parameterize WebBaseLoader with a variety of settings, allowing for specification of request headers, rate limits, and parsers and other kwargs for BeautifulSoup. See its API reference for detail.\\nAdvanced parsing‚Äã\\nThis method is appropriate if we want more granular control or processing of the page content. Below, instead of generating one Document per page and controlling its content via BeautifulSoup, we generate multiple Document objects representing distinct structures on a page. These structures can include section titles and their corresponding body texts, lists or enumerations, tables, and more.\\nUnder the hood it uses the langchain-unstructured library. See the integration docs for more information about using Unstructured with LangChain.\\nfrom langchain_unstructured import UnstructuredLoaderpage_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"loader = UnstructuredLoader(web_url=page_url)docs = []async for doc in loader.alazy_load():    docs.append(doc)API Reference:UnstructuredLoader\\nINFO: Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.INFO: NumExpr defaulting to 8 threads.\\nNote that with no advance knowledge of the page HTML structure, we recover a natural organization of the body text:\\nfor doc in docs[:5]:    print(doc.page_content)\\nHow to add memory to chatbotsA key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:Simply stuffing previous messages into a chat model prompt.The above, but trimming old messages to reduce the amount of distracting information the model has to deal with.More complex modifications like synthesizing summaries for long running conversations.ERROR! Session/line number was not unique in database. History logging moved to new session 2747\\nExtracting content from specific sections‚Äã\\nEach Document object represents an element of the page. Its metadata contains useful information, such as its category:\\nfor doc in docs[:5]:    print(f\"{doc.metadata[\\'category\\']}: {doc.page_content}\")\\nTitle: How to add memory to chatbotsNarrativeText: A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:ListItem: Simply stuffing previous messages into a chat model prompt.ListItem: The above, but trimming old messages to reduce the amount of distracting information the model has to deal with.ListItem: More complex modifications like synthesizing summaries for long running conversations.\\nElements may also have parent-child relationships -- for example, a paragraph might belong to a section with a title. If a section is of particular interest (e.g., for indexing) we can isolate the corresponding Document objects.\\nAs an example, below we load the content of the \"Setup\" sections for two web pages:\\nfrom typing import Listfrom langchain_core.documents import Documentasync def _get_setup_docs_from_url(url: str) -> List[Document]:    loader = UnstructuredLoader(web_url=url)    setup_docs = []    parent_id = -1    async for doc in loader.alazy_load():        if doc.metadata[\"category\"] == \"Title\" and doc.page_content.startswith(\"Setup\"):            parent_id = doc.metadata[\"element_id\"]        if doc.metadata.get(\"parent_id\") == parent_id:            setup_docs.append(doc)    return setup_docspage_urls = [    \"https://python.langchain.com/docs/how_to/chatbots_memory/\",    \"https://python.langchain.com/docs/how_to/chatbots_tools/\",]setup_docs = []for url in page_urls:    page_setup_docs = await _get_setup_docs_from_url(url)    setup_docs.extend(page_setup_docs)API Reference:Document\\nfrom collections import defaultdictsetup_text = defaultdict(str)for doc in setup_docs:    url = doc.metadata[\"url\"]    setup_text[url] += f\"{doc.page_content}\\\\n\"dict(setup_text)\\n{\\'https://python.langchain.com/docs/how_to/chatbots_memory/\\': \"You\\'ll need to install a few packages, and have your OpenAI API key set as an environment variable named OPENAI_API_KEY:\\\\n%pip install --upgrade --quiet langchain langchain-openai\\\\n\\\\n# Set env var OPENAI_API_KEY or load from a .env file:\\\\nimport dotenv\\\\n\\\\ndotenv.load_dotenv()\\\\n[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\\\\nYou should consider upgrading via the \\'/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip\\' command.[0m[33m\\\\n[0mNote: you may need to restart the kernel to use updated packages.\\\\n\", \\'https://python.langchain.com/docs/how_to/chatbots_tools/\\': \"For this guide, we\\'ll be using a tool calling agent with a single tool for searching the web. The default will be powered by Tavily, but you can switch it out for any similar tool. The rest of this section will assume you\\'re using Tavily.\\\\nYou\\'ll need to sign up for an account on the Tavily website, and install the following packages:\\\\n%pip install --upgrade --quiet langchain-community langchain-openai tavily-python\\\\n\\\\n# Set env var OPENAI_API_KEY or load from a .env file:\\\\nimport dotenv\\\\n\\\\ndotenv.load_dotenv()\\\\nYou will also need your OpenAI key set as OPENAI_API_KEY and your Tavily API key set as TAVILY_API_KEY.\\\\n\"}\\nVector search over page content‚Äã\\nOnce we have loaded the page contents into LangChain Document objects, we can index them (e.g., for a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain embeddings model will suffice.\\n%pip install -qU langchain-openai\\nimport getpassimport osif \"OPENAI_API_KEY\" not in os.environ:    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\\nfrom langchain_core.vectorstores import InMemoryVectorStorefrom langchain_openai import OpenAIEmbeddingsvector_store = InMemoryVectorStore.from_documents(setup_docs, OpenAIEmbeddings())retrieved_docs = vector_store.similarity_search(\"Install Tavily\", k=2)for doc in retrieved_docs:    print(f\"Page {doc.metadata[\\'url\\']}: {doc.page_content[:300]}\\\\n\")API Reference:InMemoryVectorStore | OpenAIEmbeddings\\nINFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"``````outputPage https://python.langchain.com/docs/how_to/chatbots_tools/: You\\'ll need to sign up for an account on the Tavily website, and install the following packages:Page https://python.langchain.com/docs/how_to/chatbots_tools/: For this guide, we\\'ll be using a tool calling agent with a single tool for searching the web. The default will be powered by Tavily, but you can switch it out for any similar tool. The rest of this section will assume you\\'re using Tavily.\\nOther web page loaders‚Äã\\nFor a list of available LangChain web page loaders, please see this table.Edit this pagePreviousHow to load PDFsNextHow to create a dynamic (self-constructing) chainSetupSimple and fast text extractionAdvanced parsingExtracting content from specific sectionsVector search over page contentOther web page loadersCommunityLangChain ForumTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8c6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://python.langchain.com/docs/how_to/document_loader_web/', 'title': 'How to load web pages | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'This guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4192b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How to load web pages | ü¶úÔ∏èüîó LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystemü¶úüõ†Ô∏è LangSmithü¶úüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to load web pagesOn this pageHow to load web pages\n",
      "This guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.\n",
      "LangChain integrates with a host of parsers that are appropriate for web pages. The right parser will depend on your needs. Below we demonstrate two possibilities:\n",
      "\n",
      "Simple and fast parsing, in which we recover one Document per web page with its content represented as a \"flattened\" string;\n",
      "Advanced parsing, in which we recover multiple Document objects per page, allowing one to identify and traverse sections, links, tables, and other structures.\n",
      "\n",
      "Setup‚Äã\n",
      "For the \"simple and fast\" parsing, we will need langchain-community and the beautifulsoup4 library:\n",
      "%pip install -qU langchain-community beautifulsoup4\n",
      "For advanced parsing, we will use langchain-unstructured:\n",
      "%pip install -qU langchain-unstructured\n",
      "Simple and fast text extraction‚Äã\n",
      "If you are looking for a simple string representation of text that is embedded in a web page, the method below is appropriate. It will return a list of Document objects -- one per page -- containing a single string of the page's text. Under the hood it uses the beautifulsoup4 Python library.\n",
      "LangChain document loaders implement lazy_load and its async variant, alazy_load, which return iterators of Document objects. We will use these below.\n",
      "import bs4from langchain_community.document_loaders import WebBaseLoaderpage_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"loader = WebBaseLoader(web_paths=[page_url])docs = []async for doc in loader.alazy_load():    docs.append(doc)assert len(docs) == 1doc = docs[0]API Reference:WebBaseLoader\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "print(f\"{doc.metadata}\\n\")print(doc.page_content[:500].strip())\n",
      "{'source': 'https://python.langchain.com/docs/how_to/chatbots_memory/', 'title': 'How to add memory to chatbots | \\uf8ff√º¬∂√∫√î‚àè√®\\uf8ff√º√Æ√≥ LangChain', 'description': 'A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:', 'language': 'en'}How to add memory to chatbots | Ô£ø√º¬∂√∫√î‚àè√®Ô£ø√º√Æ√≥ LangChainSkip to main contentShare your thoughts on AI agents. Take the 3-min survey.IntegrationsAPI ReferenceMoreContributingPeopleLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1Ô£ø√º√≠¬®SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a Simple LLM Application with LCELBuild a Query Analysis SystemBuild a ChatbotConversational RAGBuild an Extraction ChainBuild an AgentTaggingd\n",
      "This is essentially a dump of the text from the page's HTML. It may contain extraneous information like headings and navigation bars. If you are familiar with the expected HTML, you can specify desired <div> classes and other parameters via BeautifulSoup. Below we parse only the body text of the article:\n",
      "loader = WebBaseLoader(    web_paths=[page_url],    bs_kwargs={        \"parse_only\": bs4.SoupStrainer(class_=\"theme-doc-markdown markdown\"),    },    bs_get_text_kwargs={\"separator\": \" | \", \"strip\": True},)docs = []async for doc in loader.alazy_load():    docs.append(doc)assert len(docs) == 1doc = docs[0]\n",
      "print(f\"{doc.metadata}\\n\")print(doc.page_content[:500])\n",
      "{'source': 'https://python.langchain.com/docs/how_to/chatbots_memory/'}How to add memory to chatbots | A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including: | Simply stuffing previous messages into a chat model prompt. | The above, but trimming old messages to reduce the amount of distracting information the model has to deal with. | More complex modifications like synthesizing summaries for long running conversations. | We'll go into more detail on a few techniq\n",
      "print(doc.page_content[-500:])\n",
      "a greeting. Nemo then asks the AI how it is doing, and the AI responds that it is fine.'), | HumanMessage(content='What did I say my name was?'), | AIMessage(content='You introduced yourself as Nemo. How can I assist you today, Nemo?')] | Note that invoking the chain again will generate another summary generated from the initial summary plus new messages and so on. You could also design a hybrid approach where a certain number of messages are retained in chat history while others are summarized.\n",
      "Note that this required advance technical knowledge of how the body text is represented in the underlying HTML.\n",
      "We can parameterize WebBaseLoader with a variety of settings, allowing for specification of request headers, rate limits, and parsers and other kwargs for BeautifulSoup. See its API reference for detail.\n",
      "Advanced parsing‚Äã\n",
      "This method is appropriate if we want more granular control or processing of the page content. Below, instead of generating one Document per page and controlling its content via BeautifulSoup, we generate multiple Document objects representing distinct structures on a page. These structures can include section titles and their corresponding body texts, lists or enumerations, tables, and more.\n",
      "Under the hood it uses the langchain-unstructured library. See the integration docs for more information about using Unstructured with LangChain.\n",
      "from langchain_unstructured import UnstructuredLoaderpage_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"loader = UnstructuredLoader(web_url=page_url)docs = []async for doc in loader.alazy_load():    docs.append(doc)API Reference:UnstructuredLoader\n",
      "INFO: Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.INFO: NumExpr defaulting to 8 threads.\n",
      "Note that with no advance knowledge of the page HTML structure, we recover a natural organization of the body text:\n",
      "for doc in docs[:5]:    print(doc.page_content)\n",
      "How to add memory to chatbotsA key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:Simply stuffing previous messages into a chat model prompt.The above, but trimming old messages to reduce the amount of distracting information the model has to deal with.More complex modifications like synthesizing summaries for long running conversations.ERROR! Session/line number was not unique in database. History logging moved to new session 2747\n",
      "Extracting content from specific sections‚Äã\n",
      "Each Document object represents an element of the page. Its metadata contains useful information, such as its category:\n",
      "for doc in docs[:5]:    print(f\"{doc.metadata['category']}: {doc.page_content}\")\n",
      "Title: How to add memory to chatbotsNarrativeText: A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:ListItem: Simply stuffing previous messages into a chat model prompt.ListItem: The above, but trimming old messages to reduce the amount of distracting information the model has to deal with.ListItem: More complex modifications like synthesizing summaries for long running conversations.\n",
      "Elements may also have parent-child relationships -- for example, a paragraph might belong to a section with a title. If a section is of particular interest (e.g., for indexing) we can isolate the corresponding Document objects.\n",
      "As an example, below we load the content of the \"Setup\" sections for two web pages:\n",
      "from typing import Listfrom langchain_core.documents import Documentasync def _get_setup_docs_from_url(url: str) -> List[Document]:    loader = UnstructuredLoader(web_url=url)    setup_docs = []    parent_id = -1    async for doc in loader.alazy_load():        if doc.metadata[\"category\"] == \"Title\" and doc.page_content.startswith(\"Setup\"):            parent_id = doc.metadata[\"element_id\"]        if doc.metadata.get(\"parent_id\") == parent_id:            setup_docs.append(doc)    return setup_docspage_urls = [    \"https://python.langchain.com/docs/how_to/chatbots_memory/\",    \"https://python.langchain.com/docs/how_to/chatbots_tools/\",]setup_docs = []for url in page_urls:    page_setup_docs = await _get_setup_docs_from_url(url)    setup_docs.extend(page_setup_docs)API Reference:Document\n",
      "from collections import defaultdictsetup_text = defaultdict(str)for doc in setup_docs:    url = doc.metadata[\"url\"]    setup_text[url] += f\"{doc.page_content}\\n\"dict(setup_text)\n",
      "{'https://python.langchain.com/docs/how_to/chatbots_memory/': \"You'll need to install a few packages, and have your OpenAI API key set as an environment variable named OPENAI_API_KEY:\\n%pip install --upgrade --quiet langchain langchain-openai\\n\\n# Set env var OPENAI_API_KEY or load from a .env file:\\nimport dotenv\\n\\ndotenv.load_dotenv()\\n[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\\nYou should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m\\n[0mNote: you may need to restart the kernel to use updated packages.\\n\", 'https://python.langchain.com/docs/how_to/chatbots_tools/': \"For this guide, we'll be using a tool calling agent with a single tool for searching the web. The default will be powered by Tavily, but you can switch it out for any similar tool. The rest of this section will assume you're using Tavily.\\nYou'll need to sign up for an account on the Tavily website, and install the following packages:\\n%pip install --upgrade --quiet langchain-community langchain-openai tavily-python\\n\\n# Set env var OPENAI_API_KEY or load from a .env file:\\nimport dotenv\\n\\ndotenv.load_dotenv()\\nYou will also need your OpenAI key set as OPENAI_API_KEY and your Tavily API key set as TAVILY_API_KEY.\\n\"}\n",
      "Vector search over page content‚Äã\n",
      "Once we have loaded the page contents into LangChain Document objects, we can index them (e.g., for a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain embeddings model will suffice.\n",
      "%pip install -qU langchain-openai\n",
      "import getpassimport osif \"OPENAI_API_KEY\" not in os.environ:    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
      "from langchain_core.vectorstores import InMemoryVectorStorefrom langchain_openai import OpenAIEmbeddingsvector_store = InMemoryVectorStore.from_documents(setup_docs, OpenAIEmbeddings())retrieved_docs = vector_store.similarity_search(\"Install Tavily\", k=2)for doc in retrieved_docs:    print(f\"Page {doc.metadata['url']}: {doc.page_content[:300]}\\n\")API Reference:InMemoryVectorStore | OpenAIEmbeddings\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"``````outputPage https://python.langchain.com/docs/how_to/chatbots_tools/: You'll need to sign up for an account on the Tavily website, and install the following packages:Page https://python.langchain.com/docs/how_to/chatbots_tools/: For this guide, we'll be using a tool calling agent with a single tool for searching the web. The default will be powered by Tavily, but you can switch it out for any similar tool. The rest of this section will assume you're using Tavily.\n",
      "Other web page loaders‚Äã\n",
      "For a list of available LangChain web page loaders, please see this table.Edit this pagePreviousHow to load PDFsNextHow to create a dynamic (self-constructing) chainSetupSimple and fast text extractionAdvanced parsingExtracting content from specific sectionsVector search over page contentOther web page loadersCommunityLangChain ForumTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb398543",
   "metadata": {},
   "source": [
    "## Load the contents of a specified HTML Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384a6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load <p> tags only\n",
    "loader1 = WebBaseLoader(web_path=page_url, bs_kwargs={\"parse_only\": bs4.SoupStrainer(\"p\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3220f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = loader1.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c31fd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/how_to/document_loader_web/'}, page_content='This guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.LangChain integrates with a host of parsers that are appropriate for web pages. The right parser will depend on your needs. Below we demonstrate two possibilities:For the \"simple and fast\" parsing, we will need langchain-community and the beautifulsoup4 library:For advanced parsing, we will use langchain-unstructured:If you are looking for a simple string representation of text that is embedded in a web page, the method below is appropriate. It will return a list of Document objects -- one per page -- containing a single string of the page\\'s text. Under the hood it uses the beautifulsoup4 Python library.LangChain document loaders implement lazy_load and its async variant, alazy_load, which return iterators of Document objects. We will use these below.This is essentially a dump of the text from the page\\'s HTML. It may contain extraneous information like headings and navigation bars. If you are familiar with the expected HTML, you can specify desired <div> classes and other parameters via BeautifulSoup. Below we parse only the body text of the article:Note that this required advance technical knowledge of how the body text is represented in the underlying HTML.We can parameterize WebBaseLoader with a variety of settings, allowing for specification of request headers, rate limits, and parsers and other kwargs for BeautifulSoup. See its API reference for detail.This method is appropriate if we want more granular control or processing of the page content. Below, instead of generating one Document per page and controlling its content via BeautifulSoup, we generate multiple Document objects representing distinct structures on a page. These structures can include section titles and their corresponding body texts, lists or enumerations, tables, and more.Under the hood it uses the langchain-unstructured library. See the integration docs for more information about using Unstructured with LangChain.Note that with no advance knowledge of the page HTML structure, we recover a natural organization of the body text:Each Document object represents an element of the page. Its metadata contains useful information, such as its category:Elements may also have parent-child relationships -- for example, a paragraph might belong to a section with a title. If a section is of particular interest (e.g., for indexing) we can isolate the corresponding Document objects.As an example, below we load the content of the \"Setup\" sections for two web pages:Once we have loaded the page contents into LangChain Document objects, we can index them (e.g., for a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain embeddings model will suffice.For a list of available LangChain web page loaders, please see this table.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a9adfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.LangChain integrates with a host of parsers that are appropriate for web pages. The right parser will depend on your needs. Below we demonstrate two possibilities:For the \"simple and fast\" parsing, we will need langchain-community and the beautifulsoup4 library:For advanced parsing, we will use langchain-unstructured:If you are looking for a simple string representation of text that is embedded in a web page, the method below is appropriate. It will return a list of Document objects -- one per page -- containing a single string of the page's text. Under the hood it uses the beautifulsoup4 Python library.LangChain document loaders implement lazy_load and its async variant, alazy_load, which return iterators of Document objects. We will use these below.This is essentially a dump of the text from the page's HTML. It may contain extraneous information like headings and navigation bars. If you are familiar with the expected HTML, you can specify desired <div> classes and other parameters via BeautifulSoup. Below we parse only the body text of the article:Note that this required advance technical knowledge of how the body text is represented in the underlying HTML.We can parameterize WebBaseLoader with a variety of settings, allowing for specification of request headers, rate limits, and parsers and other kwargs for BeautifulSoup. See its API reference for detail.This method is appropriate if we want more granular control or processing of the page content. Below, instead of generating one Document per page and controlling its content via BeautifulSoup, we generate multiple Document objects representing distinct structures on a page. These structures can include section titles and their corresponding body texts, lists or enumerations, tables, and more.Under the hood it uses the langchain-unstructured library. See the integration docs for more information about using Unstructured with LangChain.Note that with no advance knowledge of the page HTML structure, we recover a natural organization of the body text:Each Document object represents an element of the page. Its metadata contains useful information, such as its category:Elements may also have parent-child relationships -- for example, a paragraph might belong to a section with a title. If a section is of particular interest (e.g., for indexing) we can isolate the corresponding Document objects.As an example, below we load the content of the \"Setup\" sections for two web pages:Once we have loaded the page contents into LangChain Document objects, we can index them (e.g., for a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain embeddings model will suffice.For a list of available LangChain web page loaders, please see this table.\n"
     ]
    }
   ],
   "source": [
    "print(docs1[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566ca968",
   "metadata": {},
   "source": [
    "## Load the contents of Multiple specified HTML Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bcabfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = WebBaseLoader(web_path=page_url, bs_kwargs={\"parse_only\":bs4.SoupStrainer([\"p\", \"ul\", \"h1\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b195fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/how_to/document_loader_web/'}, page_content='ContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.2v0.1IntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\\uf8ffü¶ú\\uf8ffüõ†Ô∏è LangSmith\\uf8ffü¶ú\\uf8ffüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to load web pagesHow to load web pagesThis guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.LangChain integrates with a host of parsers that are appropriate for web pages. The right parser will depend on your needs. Below we demonstrate two possibilities:\\nSimple and fast parsing, in which we recover one Document per web page with its content represented as a \"flattened\" string;\\nAdvanced parsing, in which we recover multiple Document objects per page, allowing one to identify and traverse sections, links, tables, and other structures.\\nFor the \"simple and fast\" parsing, we will need langchain-community and the beautifulsoup4 library:For advanced parsing, we will use langchain-unstructured:If you are looking for a simple string representation of text that is embedded in a web page, the method below is appropriate. It will return a list of Document objects -- one per page -- containing a single string of the page\\'s text. Under the hood it uses the beautifulsoup4 Python library.LangChain document loaders implement lazy_load and its async variant, alazy_load, which return iterators of Document objects. We will use these below.This is essentially a dump of the text from the page\\'s HTML. It may contain extraneous information like headings and navigation bars. If you are familiar with the expected HTML, you can specify desired <div> classes and other parameters via BeautifulSoup. Below we parse only the body text of the article:Note that this required advance technical knowledge of how the body text is represented in the underlying HTML.We can parameterize WebBaseLoader with a variety of settings, allowing for specification of request headers, rate limits, and parsers and other kwargs for BeautifulSoup. See its API reference for detail.This method is appropriate if we want more granular control or processing of the page content. Below, instead of generating one Document per page and controlling its content via BeautifulSoup, we generate multiple Document objects representing distinct structures on a page. These structures can include section titles and their corresponding body texts, lists or enumerations, tables, and more.Under the hood it uses the langchain-unstructured library. See the integration docs for more information about using Unstructured with LangChain.Note that with no advance knowledge of the page HTML structure, we recover a natural organization of the body text:Each Document object represents an element of the page. Its metadata contains useful information, such as its category:Elements may also have parent-child relationships -- for example, a paragraph might belong to a section with a title. If a section is of particular interest (e.g., for indexing) we can isolate the corresponding Document objects.As an example, below we load the content of the \"Setup\" sections for two web pages:Once we have loaded the page contents into LangChain Document objects, we can index them (e.g., for a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain embeddings model will suffice.For a list of available LangChain web page loaders, please see this table.SetupSimple and fast text extractionAdvanced parsingExtracting content from specific sectionsVector search over page contentOther web page loadersLangChain ForumTwitterOrganizationPythonJS/TSHomepageBlogYouTube')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs2 = loader2.load()\n",
    "docs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ec42a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.2v0.1IntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystemü¶úüõ†Ô∏è LangSmithü¶úüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to load web pagesHow to load web pagesThis guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.LangChain integrates with a host of parsers that are appropriate for web pages. The right parser will depend on your needs. Below we demonstrate two possibilities:\n",
      "Simple and fast parsing, in which we recover one Document per web page with its content represented as a \"flattened\" string;\n",
      "Advanced parsing, in which we recover multiple Document objects per page, allowing one to identify and traverse sections, links, tables, and other structures.\n",
      "For the \"simple and fast\" parsing, we will need langchain-community and the beautifulsoup4 library:For advanced parsing, we will use langchain-unstructured:If you are looking for a simple string representation of text that is embedded in a web page, the method below is appropriate. It will return a list of Document objects -- one per page -- containing a single string of the page's text. Under the hood it uses the beautifulsoup4 Python library.LangChain document loaders implement lazy_load and its async variant, alazy_load, which return iterators of Document objects. We will use these below.This is essentially a dump of the text from the page's HTML. It may contain extraneous information like headings and navigation bars. If you are familiar with the expected HTML, you can specify desired <div> classes and other parameters via BeautifulSoup. Below we parse only the body text of the article:Note that this required advance technical knowledge of how the body text is represented in the underlying HTML.We can parameterize WebBaseLoader with a variety of settings, allowing for specification of request headers, rate limits, and parsers and other kwargs for BeautifulSoup. See its API reference for detail.This method is appropriate if we want more granular control or processing of the page content. Below, instead of generating one Document per page and controlling its content via BeautifulSoup, we generate multiple Document objects representing distinct structures on a page. These structures can include section titles and their corresponding body texts, lists or enumerations, tables, and more.Under the hood it uses the langchain-unstructured library. See the integration docs for more information about using Unstructured with LangChain.Note that with no advance knowledge of the page HTML structure, we recover a natural organization of the body text:Each Document object represents an element of the page. Its metadata contains useful information, such as its category:Elements may also have parent-child relationships -- for example, a paragraph might belong to a section with a title. If a section is of particular interest (e.g., for indexing) we can isolate the corresponding Document objects.As an example, below we load the content of the \"Setup\" sections for two web pages:Once we have loaded the page contents into LangChain Document objects, we can index them (e.g., for a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain embeddings model will suffice.For a list of available LangChain web page loaders, please see this table.SetupSimple and fast text extractionAdvanced parsingExtracting content from specific sectionsVector search over page contentOther web page loadersLangChain ForumTwitterOrganizationPythonJS/TSHomepageBlogYouTube\n"
     ]
    }
   ],
   "source": [
    "print(docs2[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8f111d",
   "metadata": {},
   "source": [
    "## Load data from multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ec8eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_urls = [\n",
    "    \"https://python.langchain.com/docs/concepts/document_loaders/\",\n",
    "    \"https://python.langchain.com/docs/how_to/#document-loaders\",\n",
    "    \"https://python.langchain.com/docs/how_to/document_loader_web/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be0415cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader3 = WebBaseLoader(web_paths=page_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2086d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs3 = loader3.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3407fe6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/concepts/document_loaders/', 'title': 'Document loaders | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': '* Document loaders API reference', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nDocument loaders | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\\uf8ffüí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\\uf8ffü¶ú\\uf8ffüõ†Ô∏è LangSmith\\uf8ffü¶ú\\uf8ffüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyConceptual guideDocument loadersOn this pageDocument loaders\\n\\nPrerequisites\\nDocument loaders API reference\\n\\nDocument loaders are designed to load document objects. LangChain has hundreds of integrations with various data sources to load data from: Slack, Notion, Google Drive, etc.\\nIntegrations‚Äã\\nYou can find available integrations on the Document loaders integrations page.\\nInterface‚Äã\\nDocuments loaders implement the BaseLoader interface.\\nEach DocumentLoader has its own specific parameters, but they can all be invoked in the same way with the .load method or .lazy_load.\\nHere\\'s a simple example:\\nfrom langchain_community.document_loaders.csv_loader import CSVLoaderloader = CSVLoader(    ...  # <-- Integration specific parameters here)data = loader.load()API Reference:CSVLoader\\nWhen working with large datasets, you can use the .lazy_load method:\\nfor document in loader.lazy_load():    print(document)\\nRelated resources‚Äã\\nPlease see the following resources for more information:\\n\\nHow-to guides for document loaders\\nDocument API reference\\nDocument loaders integrations\\nEdit this pagePreviousChat modelsNextEmbedding modelsIntegrationsInterfaceRelated resourcesCommunityLangChain ForumTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\\n\\n'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/how_to/#document-loaders', 'title': 'How-to guides | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'Here you‚Äôll find answers to ‚ÄúHow do I‚Ä¶.?‚Äù types of questions.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nHow-to guides | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\\uf8ffüí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\\uf8ffü¶ú\\uf8ffüõ†Ô∏è LangSmith\\uf8ffü¶ú\\uf8ffüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesOn this pageHow-to guides\\nHere you‚Äôll find answers to ‚ÄúHow do I‚Ä¶.?‚Äù types of questions.\\nThese guides are goal-oriented and concrete; they\\'re meant to help you complete a specific task.\\nFor conceptual explanations see the Conceptual guide.\\nFor end-to-end walkthroughs see Tutorials.\\nFor comprehensive descriptions of every class and function see the API Reference.\\nInstallation‚Äã\\n\\nHow to: install LangChain packages\\nHow to: use LangChain with different Pydantic versions\\n\\nKey features‚Äã\\nThis highlights functionality that is core to using LangChain.\\n\\nHow to: return structured data from a model\\nHow to: use a model to call tools\\nHow to: stream runnables\\nHow to: debug your LLM apps\\n\\nComponents‚Äã\\nThese are the core building blocks you can use when building applications.\\nChat models‚Äã\\nChat Models are newer forms of language models that take messages in and output a message.\\nSee supported integrations for details on getting started with chat models from a specific provider.\\n\\nHow to: do function/tool calling\\nHow to: get models to return structured output\\nHow to: cache model responses\\nHow to: get log probabilities\\nHow to: create a custom chat model class\\nHow to: stream a response back\\nHow to: track token usage\\nHow to: track response metadata across providers\\nHow to: use chat model to call tools\\nHow to: stream tool calls\\nHow to: handle rate limits\\nHow to: few shot prompt tool behavior\\nHow to: bind model-specific formatted tools\\nHow to: force a specific tool call\\nHow to: work with local models\\nHow to: init any model in one line\\nHow to: pass multimodal data directly to models\\n\\nMessages‚Äã\\nMessages are the input and output of chat models. They have some content and a role, which describes the source of the message.\\n\\nHow to: trim messages\\nHow to: filter messages\\nHow to: merge consecutive messages of the same type\\n\\nPrompt templates‚Äã\\nPrompt Templates are responsible for formatting user input into a format that can be passed to a language model.\\n\\nHow to: use few shot examples\\nHow to: use few shot examples in chat models\\nHow to: partially format prompt templates\\nHow to: compose prompts together\\nHow to: use multimodal prompts\\n\\nExample selectors‚Äã\\nExample Selectors are responsible for selecting the correct few shot examples to pass to the prompt.\\n\\nHow to: use example selectors\\nHow to: select examples by length\\nHow to: select examples by semantic similarity\\nHow to: select examples by semantic ngram overlap\\nHow to: select examples by maximal marginal relevance\\nHow to: select examples from LangSmith few-shot datasets\\n\\nLLMs‚Äã\\nWhat LangChain calls LLMs are older forms of language models that take a string in and output a string.\\n\\nHow to: cache model responses\\nHow to: create a custom LLM class\\nHow to: stream a response back\\nHow to: track token usage\\nHow to: work with local models\\n\\nOutput parsers‚Äã\\nOutput Parsers are responsible for taking the output of an LLM and parsing into more structured format.\\n\\nHow to: parse text from message objects\\nHow to: use output parsers to parse an LLM response into structured format\\nHow to: parse JSON output\\nHow to: parse XML output\\nHow to: parse YAML output\\nHow to: retry when output parsing errors occur\\nHow to: try to fix errors in output parsing\\nHow to: write a custom output parser class\\n\\nDocument loaders‚Äã\\nDocument Loaders are responsible for loading documents from a variety of sources.\\n\\nHow to: load PDF files\\nHow to: load web pages\\nHow to: load CSV data\\nHow to: load data from a directory\\nHow to: load HTML data\\nHow to: load JSON data\\nHow to: load Markdown data\\nHow to: load Microsoft Office data\\nHow to: write a custom document loader\\n\\nText splitters‚Äã\\nText Splitters take a document and split into chunks that can be used for retrieval.\\n\\nHow to: recursively split text\\nHow to: split HTML\\nHow to: split by character\\nHow to: split code\\nHow to: split Markdown by headers\\nHow to: recursively split JSON\\nHow to: split text into semantic chunks\\nHow to: split by tokens\\n\\nEmbedding models‚Äã\\nEmbedding Models take a piece of text and create a numerical representation of it.\\nSee supported integrations for details on getting started with embedding models from a specific provider.\\n\\nHow to: embed text data\\nHow to: cache embedding results\\nHow to: create a custom embeddings class\\n\\nVector stores‚Äã\\nVector stores are databases that can efficiently store and retrieve embeddings.\\nSee supported integrations for details on getting started with vector stores from a specific provider.\\n\\nHow to: use a vector store to retrieve data\\n\\nRetrievers‚Äã\\nRetrievers are responsible for taking a query and returning relevant documents.\\n\\nHow to: use a vector store to retrieve data\\nHow to: generate multiple queries to retrieve data for\\nHow to: use contextual compression to compress the data retrieved\\nHow to: write a custom retriever class\\nHow to: add similarity scores to retriever results\\nHow to: combine the results from multiple retrievers\\nHow to: reorder retrieved results to mitigate the \"lost in the middle\" effect\\nHow to: generate multiple embeddings per document\\nHow to: retrieve the whole document for a chunk\\nHow to: generate metadata filters\\nHow to: create a time-weighted retriever\\nHow to: use hybrid vector and keyword retrieval\\n\\nIndexing‚Äã\\nIndexing is the process of keeping your vectorstore in-sync with the underlying data source.\\n\\nHow to: reindex data to keep your vectorstore in-sync with the underlying data source\\n\\nTools‚Äã\\nLangChain Tools contain a description of the tool (to pass to the language model) as well as the implementation of the function to call. Refer here for a list of pre-built tools.\\n\\nHow to: create tools\\nHow to: use built-in tools and toolkits\\nHow to: use chat models to call tools\\nHow to: pass tool outputs to chat models\\nHow to: pass run time values to tools\\nHow to: add a human-in-the-loop for tools\\nHow to: handle tool errors\\nHow to: force models to call a tool\\nHow to: disable parallel tool calling\\nHow to: access the RunnableConfig from a tool\\nHow to: stream events from a tool\\nHow to: return artifacts from a tool\\nHow to: convert Runnables to tools\\nHow to: add ad-hoc tool calling capability to models\\nHow to: pass in runtime secrets\\n\\nMultimodal‚Äã\\n\\nHow to: pass multimodal data directly to models\\nHow to: use multimodal prompts\\n\\nAgents‚Äã\\nnoteFor in depth how-to guides for agents, please check out LangGraph documentation.\\n\\nHow to: use legacy LangChain Agents (AgentExecutor)\\nHow to: migrate from legacy LangChain agents to LangGraph\\n\\nCallbacks‚Äã\\nCallbacks allow you to hook into the various stages of your LLM application\\'s execution.\\n\\nHow to: pass in callbacks at runtime\\nHow to: attach callbacks to a module\\nHow to: pass callbacks into a module constructor\\nHow to: create custom callback handlers\\nHow to: use callbacks in async environments\\nHow to: dispatch custom callback events\\n\\nCustom‚Äã\\nAll of LangChain components can easily be extended to support your own versions.\\n\\nHow to: create a custom chat model class\\nHow to: create a custom LLM class\\nHow to: create a custom embeddings class\\nHow to: write a custom retriever class\\nHow to: write a custom document loader\\nHow to: write a custom output parser class\\nHow to: create custom callback handlers\\nHow to: define a custom tool\\nHow to: dispatch custom callback events\\n\\nSerialization‚Äã\\n\\nHow to: save and load LangChain objects\\n\\nUse cases‚Äã\\nThese guides cover use-case specific details.\\nQ&A with RAG‚Äã\\nRetrieval Augmented Generation (RAG) is a way to connect LLMs to external sources of data.\\nFor a high-level tutorial on RAG, check out this guide.\\n\\nHow to: add chat history\\nHow to: stream\\nHow to: return sources\\nHow to: return citations\\nHow to: do per-user retrieval\\n\\nExtraction‚Äã\\nExtraction is when you use LLMs to extract structured information from unstructured text.\\nFor a high level tutorial on extraction, check out this guide.\\n\\nHow to: use reference examples\\nHow to: handle long text\\nHow to: do extraction without using function calling\\n\\nChatbots‚Äã\\nChatbots involve using an LLM to have a conversation.\\nFor a high-level tutorial on building chatbots, check out this guide.\\n\\nHow to: manage memory\\nHow to: do retrieval\\nHow to: use tools\\nHow to: manage large chat history\\n\\nQuery analysis‚Äã\\nQuery Analysis is the task of using an LLM to generate a query to send to a retriever.\\nFor a high-level tutorial on query analysis, check out this guide.\\n\\nHow to: add examples to the prompt\\nHow to: handle cases where no queries are generated\\nHow to: handle multiple queries\\nHow to: handle multiple retrievers\\nHow to: construct filters\\nHow to: deal with high cardinality categorical variables\\n\\nQ&A over SQL + CSV‚Äã\\nYou can use LLMs to do question answering over tabular data.\\nFor a high-level tutorial, check out this guide.\\n\\nHow to: use prompting to improve results\\nHow to: do query validation\\nHow to: deal with large databases\\nHow to: deal with CSV files\\n\\nQ&A over graph databases‚Äã\\nYou can use an LLM to do question answering over graph databases.\\nFor a high-level tutorial, check out this guide.\\n\\nHow to: add a semantic layer over the database\\nHow to: construct knowledge graphs\\n\\nSummarization‚Äã\\nLLMs can summarize and otherwise distill desired information from text, including\\nlarge volumes of text. For a high-level tutorial, check out this guide.\\n\\nHow to: summarize text in a single LLM call\\nHow to: summarize text through parallelization\\nHow to: summarize text through iterative refinement\\n\\nLangChain Expression Language (LCEL)‚Äã\\nShould I use LCEL?LCEL is an orchestration solution. See our\\nconcepts page for recommendations on when to\\nuse LCEL.\\nLangChain Expression Language is a way to create arbitrary custom chains. It is built on the Runnable protocol.\\nLCEL cheatsheet: For a quick overview of how to use the main LCEL primitives.\\nMigration guide: For migrating legacy chain abstractions to LCEL.\\n\\nHow to: chain runnables\\nHow to: stream runnables\\nHow to: invoke runnables in parallel\\nHow to: add default invocation args to runnables\\nHow to: turn any function into a runnable\\nHow to: pass through inputs from one chain step to the next\\nHow to: configure runnable behavior at runtime\\nHow to: add message history (memory) to a chain\\nHow to: route between sub-chains\\nHow to: create a dynamic (self-constructing) chain\\nHow to: inspect runnables\\nHow to: add fallbacks to a runnable\\nHow to: pass runtime secrets to a runnable\\n\\nLangGraph‚Äã\\nLangGraph is an extension of LangChain aimed at\\nbuilding robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.\\nLangGraph documentation is currently hosted on a separate site.\\nYou can peruse LangGraph how-to guides here.\\nLangSmith‚Äã\\nLangSmith allows you to closely trace, monitor and evaluate your LLM application.\\nIt seamlessly integrates with LangChain and LangGraph, and you can use it to inspect and debug individual steps of your chains and agents as you build.\\nLangSmith documentation is hosted on a separate site.\\nYou can peruse LangSmith how-to guides here, but we\\'ll highlight a few sections that are particularly\\nrelevant to LangChain below:\\nEvaluation‚Äã\\n\\nEvaluating performance is a vital part of building LLM-powered applications.\\nLangSmith helps with every step of the process from creating a dataset to defining metrics to running evaluators.\\nTo learn more, check out the LangSmith evaluation how-to guides.\\nTracing‚Äã\\n\\nTracing gives you observability inside your chains and agents, and is vital in diagnosing issues.\\n\\nHow to: trace with LangChain\\nHow to: add metadata and tags to traces\\n\\nYou can see general tracing-related how-tos in this section of the LangSmith docs.Edit this pagePreviousSummarize TextNextHow-to guidesInstallationKey featuresComponentsChat modelsMessagesPrompt templatesExample selectorsLLMsOutput parsersDocument loadersText splittersEmbedding modelsVector storesRetrieversIndexingToolsMultimodalAgentsCallbacksCustomSerializationUse casesQ&A with RAGExtractionChatbotsQuery analysisQ&A over SQL + CSVQ&A over graph databasesSummarizationLangChain Expression Language (LCEL)LangGraphLangSmithEvaluationTracingCommunityLangChain ForumTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\\n\\n'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/how_to/document_loader_web/', 'title': 'How to load web pages | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'This guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nHow to load web pages | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1\\uf8ffüí¨SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem\\uf8ffü¶ú\\uf8ffüõ†Ô∏è LangSmith\\uf8ffü¶ú\\uf8ffüï∏Ô∏è LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyHow-to guidesHow to load web pagesOn this pageHow to load web pages\\nThis guide covers how to load web pages into the LangChain Document format that we use downstream. Web pages contain text, images, and other multimedia elements, and are typically represented with HTML. They may include links to other pages or resources.\\nLangChain integrates with a host of parsers that are appropriate for web pages. The right parser will depend on your needs. Below we demonstrate two possibilities:\\n\\nSimple and fast parsing, in which we recover one Document per web page with its content represented as a \"flattened\" string;\\nAdvanced parsing, in which we recover multiple Document objects per page, allowing one to identify and traverse sections, links, tables, and other structures.\\n\\nSetup‚Äã\\nFor the \"simple and fast\" parsing, we will need langchain-community and the beautifulsoup4 library:\\n%pip install -qU langchain-community beautifulsoup4\\nFor advanced parsing, we will use langchain-unstructured:\\n%pip install -qU langchain-unstructured\\nSimple and fast text extraction‚Äã\\nIf you are looking for a simple string representation of text that is embedded in a web page, the method below is appropriate. It will return a list of Document objects -- one per page -- containing a single string of the page\\'s text. Under the hood it uses the beautifulsoup4 Python library.\\nLangChain document loaders implement lazy_load and its async variant, alazy_load, which return iterators of Document objects. We will use these below.\\nimport bs4from langchain_community.document_loaders import WebBaseLoaderpage_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"loader = WebBaseLoader(web_paths=[page_url])docs = []async for doc in loader.alazy_load():    docs.append(doc)assert len(docs) == 1doc = docs[0]API Reference:WebBaseLoader\\nUSER_AGENT environment variable not set, consider setting it to identify your requests.\\nprint(f\"{doc.metadata}\\\\n\")print(doc.page_content[:500].strip())\\n{\\'source\\': \\'https://python.langchain.com/docs/how_to/chatbots_memory/\\', \\'title\\': \\'How to add memory to chatbots | \\\\uf8ff√º¬∂√∫√î‚àè√®\\\\uf8ff√º√Æ√≥ LangChain\\', \\'description\\': \\'A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:\\', \\'language\\': \\'en\\'}How to add memory to chatbots | Ô£ø√º¬∂√∫√î‚àè√®Ô£ø√º√Æ√≥ LangChainSkip to main contentShare your thoughts on AI agents. Take the 3-min survey.IntegrationsAPI ReferenceMoreContributingPeopleLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1Ô£ø√º√≠¬®SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a Simple LLM Application with LCELBuild a Query Analysis SystemBuild a ChatbotConversational RAGBuild an Extraction ChainBuild an AgentTaggingd\\nThis is essentially a dump of the text from the page\\'s HTML. It may contain extraneous information like headings and navigation bars. If you are familiar with the expected HTML, you can specify desired <div> classes and other parameters via BeautifulSoup. Below we parse only the body text of the article:\\nloader = WebBaseLoader(    web_paths=[page_url],    bs_kwargs={        \"parse_only\": bs4.SoupStrainer(class_=\"theme-doc-markdown markdown\"),    },    bs_get_text_kwargs={\"separator\": \" | \", \"strip\": True},)docs = []async for doc in loader.alazy_load():    docs.append(doc)assert len(docs) == 1doc = docs[0]\\nprint(f\"{doc.metadata}\\\\n\")print(doc.page_content[:500])\\n{\\'source\\': \\'https://python.langchain.com/docs/how_to/chatbots_memory/\\'}How to add memory to chatbots | A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including: | Simply stuffing previous messages into a chat model prompt. | The above, but trimming old messages to reduce the amount of distracting information the model has to deal with. | More complex modifications like synthesizing summaries for long running conversations. | We\\'ll go into more detail on a few techniq\\nprint(doc.page_content[-500:])\\na greeting. Nemo then asks the AI how it is doing, and the AI responds that it is fine.\\'), | HumanMessage(content=\\'What did I say my name was?\\'), | AIMessage(content=\\'You introduced yourself as Nemo. How can I assist you today, Nemo?\\')] | Note that invoking the chain again will generate another summary generated from the initial summary plus new messages and so on. You could also design a hybrid approach where a certain number of messages are retained in chat history while others are summarized.\\nNote that this required advance technical knowledge of how the body text is represented in the underlying HTML.\\nWe can parameterize WebBaseLoader with a variety of settings, allowing for specification of request headers, rate limits, and parsers and other kwargs for BeautifulSoup. See its API reference for detail.\\nAdvanced parsing‚Äã\\nThis method is appropriate if we want more granular control or processing of the page content. Below, instead of generating one Document per page and controlling its content via BeautifulSoup, we generate multiple Document objects representing distinct structures on a page. These structures can include section titles and their corresponding body texts, lists or enumerations, tables, and more.\\nUnder the hood it uses the langchain-unstructured library. See the integration docs for more information about using Unstructured with LangChain.\\nfrom langchain_unstructured import UnstructuredLoaderpage_url = \"https://python.langchain.com/docs/how_to/chatbots_memory/\"loader = UnstructuredLoader(web_url=page_url)docs = []async for doc in loader.alazy_load():    docs.append(doc)API Reference:UnstructuredLoader\\nINFO: Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.INFO: NumExpr defaulting to 8 threads.\\nNote that with no advance knowledge of the page HTML structure, we recover a natural organization of the body text:\\nfor doc in docs[:5]:    print(doc.page_content)\\nHow to add memory to chatbotsA key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:Simply stuffing previous messages into a chat model prompt.The above, but trimming old messages to reduce the amount of distracting information the model has to deal with.More complex modifications like synthesizing summaries for long running conversations.ERROR! Session/line number was not unique in database. History logging moved to new session 2747\\nExtracting content from specific sections‚Äã\\nEach Document object represents an element of the page. Its metadata contains useful information, such as its category:\\nfor doc in docs[:5]:    print(f\"{doc.metadata[\\'category\\']}: {doc.page_content}\")\\nTitle: How to add memory to chatbotsNarrativeText: A key feature of chatbots is their ability to use content of previous conversation turns as context. This state management can take several forms, including:ListItem: Simply stuffing previous messages into a chat model prompt.ListItem: The above, but trimming old messages to reduce the amount of distracting information the model has to deal with.ListItem: More complex modifications like synthesizing summaries for long running conversations.\\nElements may also have parent-child relationships -- for example, a paragraph might belong to a section with a title. If a section is of particular interest (e.g., for indexing) we can isolate the corresponding Document objects.\\nAs an example, below we load the content of the \"Setup\" sections for two web pages:\\nfrom typing import Listfrom langchain_core.documents import Documentasync def _get_setup_docs_from_url(url: str) -> List[Document]:    loader = UnstructuredLoader(web_url=url)    setup_docs = []    parent_id = -1    async for doc in loader.alazy_load():        if doc.metadata[\"category\"] == \"Title\" and doc.page_content.startswith(\"Setup\"):            parent_id = doc.metadata[\"element_id\"]        if doc.metadata.get(\"parent_id\") == parent_id:            setup_docs.append(doc)    return setup_docspage_urls = [    \"https://python.langchain.com/docs/how_to/chatbots_memory/\",    \"https://python.langchain.com/docs/how_to/chatbots_tools/\",]setup_docs = []for url in page_urls:    page_setup_docs = await _get_setup_docs_from_url(url)    setup_docs.extend(page_setup_docs)API Reference:Document\\nfrom collections import defaultdictsetup_text = defaultdict(str)for doc in setup_docs:    url = doc.metadata[\"url\"]    setup_text[url] += f\"{doc.page_content}\\\\n\"dict(setup_text)\\n{\\'https://python.langchain.com/docs/how_to/chatbots_memory/\\': \"You\\'ll need to install a few packages, and have your OpenAI API key set as an environment variable named OPENAI_API_KEY:\\\\n%pip install --upgrade --quiet langchain langchain-openai\\\\n\\\\n# Set env var OPENAI_API_KEY or load from a .env file:\\\\nimport dotenv\\\\n\\\\ndotenv.load_dotenv()\\\\n[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\\\\nYou should consider upgrading via the \\'/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip\\' command.[0m[33m\\\\n[0mNote: you may need to restart the kernel to use updated packages.\\\\n\", \\'https://python.langchain.com/docs/how_to/chatbots_tools/\\': \"For this guide, we\\'ll be using a tool calling agent with a single tool for searching the web. The default will be powered by Tavily, but you can switch it out for any similar tool. The rest of this section will assume you\\'re using Tavily.\\\\nYou\\'ll need to sign up for an account on the Tavily website, and install the following packages:\\\\n%pip install --upgrade --quiet langchain-community langchain-openai tavily-python\\\\n\\\\n# Set env var OPENAI_API_KEY or load from a .env file:\\\\nimport dotenv\\\\n\\\\ndotenv.load_dotenv()\\\\nYou will also need your OpenAI key set as OPENAI_API_KEY and your Tavily API key set as TAVILY_API_KEY.\\\\n\"}\\nVector search over page content‚Äã\\nOnce we have loaded the page contents into LangChain Document objects, we can index them (e.g., for a RAG application) in the usual way. Below we use OpenAI embeddings, although any LangChain embeddings model will suffice.\\n%pip install -qU langchain-openai\\nimport getpassimport osif \"OPENAI_API_KEY\" not in os.environ:    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\\nfrom langchain_core.vectorstores import InMemoryVectorStorefrom langchain_openai import OpenAIEmbeddingsvector_store = InMemoryVectorStore.from_documents(setup_docs, OpenAIEmbeddings())retrieved_docs = vector_store.similarity_search(\"Install Tavily\", k=2)for doc in retrieved_docs:    print(f\"Page {doc.metadata[\\'url\\']}: {doc.page_content[:300]}\\\\n\")API Reference:InMemoryVectorStore | OpenAIEmbeddings\\nINFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"``````outputPage https://python.langchain.com/docs/how_to/chatbots_tools/: You\\'ll need to sign up for an account on the Tavily website, and install the following packages:Page https://python.langchain.com/docs/how_to/chatbots_tools/: For this guide, we\\'ll be using a tool calling agent with a single tool for searching the web. The default will be powered by Tavily, but you can switch it out for any similar tool. The rest of this section will assume you\\'re using Tavily.\\nOther web page loaders‚Äã\\nFor a list of available LangChain web page loaders, please see this table.Edit this pagePreviousHow to load PDFsNextHow to create a dynamic (self-constructing) chainSetupSimple and fast text extractionAdvanced parsingExtracting content from specific sectionsVector search over page contentOther web page loadersCommunityLangChain ForumTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3807179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
